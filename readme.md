üìö BookScraper & SQL Insights

Web Scraping + Modelado Relacional + An√°lisis SQL

Este proyecto implementa un pipeline completo de datos (End-to-End) que:

Extrae informaci√≥n desde un sitio web real mediante Web Scraping

Limpia y transforma los datos

Los estructura en una base de datos relacional optimizada

El objetivo no es solo obtener datos, sino convertir informaci√≥n no estructurada en conocimiento consultable aplicando principios reales de ingenier√≠a de datos y modelado.

üöÄ Qu√© hace el sistema

El flujo del proyecto se compone de tres etapas:

1. Extracci√≥n de datos

Se realiza scraping sobre:

books.toscrape.com

Extrayendo:

T√≠tulo

Categor√≠a

Precio

Stock

Calificaci√≥n

El sistema navega autom√°ticamente por:

categor√≠as

paginaci√≥n

p√°ginas individuales de cada libro

Incluye manejo de errores y reintentos para robustez.

2. Transformaci√≥n

Los datos recolectados pasan por un proceso de limpieza:

Conversi√≥n de precios con Regex

Normalizaci√≥n de calificaciones (texto ‚Üí valor num√©rico)

Estandarizaci√≥n de stock

Adem√°s:

Se simulan autores

Se generan relaciones complejas

Algunos libros poseen m√∫ltiples autores

Esto permite modelar escenarios reales y no solo datos planos.

3. Persistencia Relacional

Los datos se almacenan en una base SQLite estructurada bajo principios de normalizaci√≥n.

Tablas principales:

Libros

Autores

Categorias

Tabla puente:

Libro_Autor

Esta estructura implementa una relaci√≥n:

Libros (N) ‚ü∑ (M) Autores

üß© Modelo de Datos

El dise√±o de la base sigue buenas pr√°cticas de modelado relacional:

Categorias (1) ‚îÄ‚îÄ‚îÄ‚îÄ (N) Libros
Libros (N) ‚îÄ‚îÄ‚îÄ‚îÄ (M) Autores

Resuelto mediante:

Libro_Autor

El proyecto incluye un Diagrama UML del esquema de base de datos ubicado en:

imagenes/

Esto permite visualizar claramente:

entidades

relaciones

cardinalidades

‚öôÔ∏è Optimizaci√≥n de Rendimiento

Se implementan √≠ndices SQL para mejorar tiempos de consulta.

Ejemplo:

B√∫squeda de libros con calificaci√≥n m√°xima:

Sin √≠ndice ‚Üí 0.00525 s

Con √≠ndice ‚Üí 0.00201 s

Resultado: reducci√≥n superior al 60% en tiempo de lectura.

üîç Consultas SQL Destacadas

Many-to-Many Join

Obtenci√≥n de libros por autor:

SELECT a.nombre AS autor, l.titulo AS libro, l.calificacion
FROM Libros l
JOIN Libro_Autor la ON l.id = la.id_libro
JOIN Autores a ON la.id_autor = a.id
ORDER BY a.nombre;

An√°lisis por Categor√≠a

Promedio de calificaci√≥n:

SELECT c.nombre AS categoria, AVG(l.calificacion) AS promedio
FROM Categorias c
JOIN Libros l ON c.id = l.id_categoria
GROUP BY c.nombre
ORDER BY promedio DESC;

üõ†Ô∏è Tecnolog√≠as Utilizadas

Python 3.11+

Requests

BeautifulSoup4

SQLite3

JSON

SQL

üß† Qu√© demuestra este proyecto

M√°s all√° del scraping, este sistema muestra:

Pipeline de datos real

Limpieza y transformaci√≥n

Modelado relacional

Implementaci√≥n de M2M

Uso de √≠ndices

Consultas anal√≠ticas

Es decir:

pasar de web ‚Üí a estructura ‚Üí a an√°lisis.

‚ñ∂Ô∏è Ejecuci√≥n

Clonar repositorio:

git clone https://github.com/Andylopez-3/Challenge-Web-Scraping-SQL.git


Instalar dependencias:

pip install requests beautifulsoup4


Ejecutar:

Abrir y correr:

Scrapiiing.ipynb

üéØ Enfoque Acad√©mico

El proyecto simula un escenario real de ingesti√≥n de datos donde:

los datos no nacen limpios
ni estructurados

pero terminan en una base lista para:

an√°lisis

visualizaci√≥n

consultas complejas