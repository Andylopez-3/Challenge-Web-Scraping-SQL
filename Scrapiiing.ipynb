{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELDA 1: Librerías e Inicialización\n",
    "# =========================\n",
    "import requests  # Para hacer solicitudes HTTP\n",
    "from bs4 import BeautifulSoup   # Para parsear HTML\n",
    "import json              # para filtrar los datos scrapeados\n",
    "import sqlite3                         # es una base de datos ligera y relacional que se almacena en un solo archivo\n",
    "import time           # Para manejar retrasos entre solicitudes\n",
    "import re                # Para operaciones con expresiones regulares\n",
    "from urllib.parse import urljoin              # Para manejar URLs\n",
    "import random                       # Para generar autores aleatorios\n",
    "\n",
    "# Base URL para concatenar rutas\n",
    "URL_BASE = \"https://books.toscrape.com/\"                  # URL base del sitio web a scrapear\n",
    "\n",
    "# Lista de autores ficticios para simular datos M2M\n",
    "AUTORES_FICTICIOS = [\n",
    "    \"Oscar Lopez\", \"jose perez\", \"juana de armas\", \"Ava Lunam\",\n",
    "    \"Kaelen Rhys\", \"Seraphina Key\", \"Jaxon Bellwether\", \"Nadia Volkov\",\n",
    "    \"Quinn Sparrow\", \"Talon Cross\", \"Viola Frost\", \"Zane O’Connell\",\"Laura Benítez\",\n",
    "    \"Diego Montenegro\", \"Sofía Rivas\", \"Martín López\", \"Camila Duarte\",\n",
    "    \"Julián Barrios\", \"Valentina Coronel\", \"Andrés Maldonado\", \"Paula Sosa\", \"Ricardo Vázquez\",\n",
    "    \"Elena Caballero\", \"Tomás Ferreira\", \"Gabriela Ayala\", \"Lucas Giménez\", \"Daniela Ortiz\",\n",
    "    \"Federico Román\", \"María Villalba\", \"Gustavo Cabrera\", \"Nadia Paredes\", \"Bruno Acosta\",\n",
    "    \"Leticia Moreno\", \"Rodrigo Vera\", \"Ana Quiñónez\", \"Sebastián Roldán\", \"Carla Medina\"\n",
    "]\n",
    "\n",
    "mapeo_calificacion_texto_a_numero = {             # Mapeo de calificaciones de texto a números\n",
    "    \"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELDA 2: Funciones de Scraping \n",
    "# =========================\n",
    "\n",
    "def obtener_sopa_html(url):\n",
    "    \"\"\"Obtiene el HTML de una URL con reintentos y manejo de errores.\"\"\"\n",
    "    for _ in range(3):          # Intenta hasta 3 veces\n",
    "        try:\n",
    "            respuesta_http = requests.get(url, timeout=10)        # Realiza la solicitud HTTP y tiene un tiempo de espera de 10 segundos\n",
    "            respuesta_http.raise_for_status()                      # Lanza un error si la respuesta HTTP no es exitosa\n",
    "            return BeautifulSoup(respuesta_http.text, \"html.parser\")   #BeautifulSoup transforma el HTML en un mapa navegable, donde podemos ir directamente a los datos que nos interesa\n",
    "        except requests.exceptions.RequestException as e:                     # Captura cualquier excepción relacionada con la solicitud HTTP\n",
    "            print(f\"Error HTTP en {url}: {e}. Reintentando...\")\n",
    "            time.sleep(1)              # Espera 1 segundo antes de reintentar\n",
    "    raise Exception(f\"No se pudo obtener el HTML de {url} después de varios intentos.\")       # Si falla después de 3 intentos, lanza una excepción\n",
    "\n",
    "\n",
    "def obtener_libros_por_categoria(nombre_categoria, url_categoria):\n",
    "    \"\"\"Recorre todas las páginas de una categoría y extrae datos clave.\"\"\"\n",
    "    libros_lista = []   # Lista para almacenar los libros encontrados\n",
    "    url_pagina = url_categoria    # URL inicial de la categoría\n",
    "\n",
    "    while True:\n",
    "        sopa_pagina = obtener_sopa_html(url_pagina)             # Obtiene el HTML de la página actual\n",
    "        \n",
    "        elementos_libros = sopa_pagina.select(\"article.product_pod h3 a\")                 # Selecciona todos los elementos de libro en la página actual\n",
    "        for libro_elemento in elementos_libros:            # Itera sobre cada libro encontrado\n",
    "            titulo_libro = libro_elemento.get(\"title\")       # Extrae el título del libro\n",
    "            url_detalle = urljoin(URL_BASE + \"catalogue/\", libro_elemento[\"href\"].replace(\"../\", \"\"))      # Construye la URL completa de la página de detalle del libro\n",
    "            \n",
    "            libros_lista.append({        # Agrega un diccionario con los datos clave del libro a la lista\n",
    "                \"titulo\": titulo_libro,\n",
    "                \"categoria\": nombre_categoria,\n",
    "                \"url\": url_detalle\n",
    "            })\n",
    "\n",
    "        # Paginación: si hay siguiente página, actualizar url_pagina; si no, terminar\n",
    "        next_link = sopa_pagina.select_one(\"li.next a\")\n",
    "        if next_link:\n",
    "            url_pagina = urljoin(url_pagina, next_link[\"href\"])   # Actualiza la URL para la siguiente página\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        time.sleep(0.5)  # Evita sobrecargar el servidor\n",
    "\n",
    "    return libros_lista\n",
    "\n",
    "\n",
    "def rasguear_detalles_libro(diccionario_libro):\n",
    "    \"\"\"Extrae precio, calificación, stock y autor de la página de detalle.\"\"\"\n",
    "    sopa_detalle = obtener_sopa_html(diccionario_libro[\"url\"])     # Obtiene el HTML de la página de detalle del libro\n",
    "    \n",
    "    # Precio (limpiando símbolos)\n",
    "    precio_texto = sopa_detalle.select_one(\".price_color\").text\n",
    "    precio_numerico = float(re.sub(r\"[^0-9.]\", \"\", precio_texto.replace(\"Â\", \"\").strip())) # Elimina símbolos y convierte a float\n",
    "    \n",
    "    # Calificación   \n",
    "    calificacion_texto_original = sopa_detalle.select_one(\".star-rating\")[\"class\"][1]          # Extrae la clase que indica la calificación\n",
    "    calificacion_numero_convertida = mapeo_calificacion_texto_a_numero.get(calificacion_texto_original, 0)   # Convierte texto a número usando el mapeo\n",
    "    \n",
    "    # Stock\n",
    "    stock_disponible = sopa_detalle.select_one(\".availability\").text.strip() # Extrae el texto de disponibilidad\n",
    "    coincidencia_numero_stock = re.search(r'\\d+', stock_disponible)    # Busca el número en el texto de disponibilidad\n",
    "    stock_numero_extraido = int(coincidencia_numero_stock.group()) if coincidencia_numero_stock else 0\n",
    "\n",
    "   \n",
    "    nombre_autor = random.choice(AUTORES_FICTICIOS)        # Selecciona un autor ficticio aleatorio\n",
    "\n",
    "    diccionario_libro.update({   # Actualiza el diccionario del libro con los nuevos datos extraídos\n",
    "        \"precio\": precio_numerico,\n",
    "        \"calificacion\": calificacion_numero_convertida,\n",
    "        \"stock\": stock_numero_extraido,\n",
    "        \"autor_scrapeado\": nombre_autor  \n",
    "    })\n",
    "    return diccionario_libro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34625f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELDA 3: Scrapeo completo\n",
    "# =========================\n",
    "def obtener_categorias():              # Obtiene todas las categorías disponibles en la página principal\n",
    "    sopa = obtener_sopa_html(URL_BASE)   # Obtiene el HTML de la página principal\n",
    "    lista = [] # Lista para almacenar las categorías\n",
    "    # Ignoramos la primera categoría \"Books\" que es la página principal\n",
    "    for cat in sopa.select(\".side_categories ul li ul li a\"):\n",
    "        nombre = cat.text.strip()\n",
    "        url = urljoin(URL_BASE, cat[\"href\"]) # Construye la URL completa de la categoría\n",
    "        lista.append((nombre, url))\n",
    "    return lista\n",
    "\n",
    "todos_libros_scraped = []          #Lista para almacenar todos los libros scrapeados\n",
    "\n",
    "categorias_disponibles = obtener_categorias()   # Obtiene todas las categorías disponibles\n",
    "for nombre_cat, url_cat in categorias_disponibles: #Itera sobre cada categoría\n",
    "    print(f\"Scrapeando categoría: {nombre_cat}\")     \n",
    "    libros_categoria_actual = obtener_libros_por_categoria(nombre_cat, url_cat) #   Obtiene todos los libros de la categoría actual\n",
    "    for libro_dict in libros_categoria_actual:      #Itera sobre cada libro en la categoría actual\n",
    "        try:\n",
    "            todos_libros_scraped.append(rasguear_detalles_libro(libro_dict)) # Extrae y agrega los detalles del libro\n",
    "        except Exception as e: #    Captura errores individuales sin detener todo el proceso\n",
    "            print(f\"Error al scrapear detalles de {libro_dict['url']}: {e}\")\n",
    "        time.sleep(0.2)  # Pequeño delay\n",
    "        \n",
    "print(f\"Scrapeo completado. Total libros: {len(todos_libros_scraped)}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datos_de_libros.json\", \"w\", encoding=\"utf-8\") as archivo_json: # Guarda los datos scrapeados en un archivo JSON\n",
    "    json.dump(todos_libros_scraped, archivo_json, indent=2, ensure_ascii=False)       # Indenta el JSON para mejor legibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7759f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema de base de datos 'Libros.db' creado con estructura M2M.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CELDA 4: Crear base de datos SQLite (DDL)\n",
    "# =========================\n",
    "NOMBRE_BD = \"Libros.db\"\n",
    "conexion_base_datos = sqlite3.connect(NOMBRE_BD)  # Conecta (o crea) la base de datos SQLite\n",
    "cursor_operaciones = conexion_base_datos.cursor()   # Crea un cursor para ejecutar comandos SQL\n",
    "\n",
    "cursor_operaciones.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Autores (                     \n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,             # Identificador único para cada autor\n",
    "    nombre TEXT UNIQUE                                  # Nombre del autor único\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor_operaciones.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Categorias (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,                  # Identificador único para cada categoría\n",
    "    nombre TEXT UNIQUE                                         # Nombre de la categoría único\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor_operaciones.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Libros (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,               # Identificador único para cada libro\n",
    "    titulo TEXT,                                          # Título del libro\n",
    "    precio REAL,                                            # Precio del libro\n",
    "    calificacion INTEGER,                                  # Calificación del libro\n",
    "    stock INTEGER,                                          # Stock disponible del libro\n",
    "    id_categoria INTEGER,                                      # Identificador de la categoría del libro\n",
    "    FOREIGN KEY(id_categoria) REFERENCES Categorias(id)              # Llave foránea a la tabla Categorias\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor_operaciones.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Libro_Autor (\n",
    "    id_libro INTEGER,                                              ## Identificador del libro\n",
    "    id_autor INTEGER,                                             ## Identificador del autor\n",
    "    PRIMARY KEY (id_libro, id_autor),                                      # Llave primaria compuesta\n",
    "    FOREIGN KEY (id_libro) REFERENCES Libros(id),                         # Llave foránea a la tabla Libros\n",
    "    FOREIGN KEY (id_autor) REFERENCES Autores(id)                           # Llave foránea a la tabla Autores\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conexion_base_datos.commit()                            # Guarda los cambios y crea las tablas\n",
    "print(f\"Esquema de base de datos '{NOMBRE_BD}' creado con estructura M2M.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d137c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorías insertadas: 50 únicas.\n",
      "Base de datos poblada con 1000 libros y relaciones M2M simuladas.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CELDA 5: Insertar datos en DB\n",
    "# ========================= \n",
    "with open(\"datos_de_libros.json\", \"r\", encoding=\"utf-8\") as archivo_json:   # Abre el archivo JSON con los datos scrapeados\n",
    "    lista_datos_libros = json.load(archivo_json)          # Carga los datos en una lista de diccionarios\n",
    "\n",
    "# Insertar categorías\n",
    "categorias_a_insertar = list(set([item[\"categoria\"] # Extrae categorías únicas y la convierte en una lista , para luego iterar e insertarlas\n",
    "for item in lista_datos_libros \n",
    "if \"categoria\" in item]))  #se corrobora que la categoría exista\n",
    "for cat_nombre in categorias_a_insertar: # Inserta cada categoría en la base de datos\n",
    "    cursor_operaciones.execute(\"INSERT OR IGNORE INTO Categorias(nombre) VALUES(?)\", (cat_nombre,)) # Inserta la categoría si no existe\n",
    "conexion_base_datos.commit()\n",
    "print(f\"Categorías insertadas: {len(categorias_a_insertar)} únicas.\") # Insertar autores\n",
    "\n",
    "# Insertar autores\n",
    "autores_reales = [item[\"autor_scrapeado\"]  # Extrae autores reales\n",
    "for item in lista_datos_libros  # Itera sobre cada libro\n",
    "if \"autor_scrapeado\" in item]       # Filtra solo los libros con autor_scrapeado\n",
    "autores_a_insertar = list(set(autores_reales + AUTORES_FICTICIOS)) # Combina autores reales y ficticios\n",
    "for autor in autores_a_insertar:     # Inserta cada autor en la base de datos\n",
    "    cursor_operaciones.execute(\"INSERT OR IGNORE INTO Autores(nombre) VALUES(?)\", (autor,)) # Inserta el autor si no existe\n",
    "conexion_base_datos.commit()\n",
    "\n",
    "# IDs de autores ficticios para llenar la tabla intermedia , o  de relacion muchos a muchos\n",
    "placeholders = ', '.join(['?'] * len(AUTORES_FICTICIOS))   # placeholders es un marcador de posición para la consulta SQL , llena de signos de interrogación según el número de autores ficticios\n",
    "query_ids_ficticios = f\"SELECT id FROM Autores WHERE nombre IN ({placeholders})\"      #El formulario ya está hecho, los datos se llenan después.\n",
    "cursor_operaciones.execute(query_ids_ficticios, AUTORES_FICTICIOS)   # Ejecuta la consulta para obtener los IDs\n",
    "ids_autores_ficticios = [row[0] for row in cursor_operaciones.fetchall()] # Lista de IDs de autores ficticios ,Obtengo los IDs para saber qué autor es quién\n",
    "# el fetchall() me devuelve una lista de tuplas, cada tupla contiene un solo elemento (el ID del autor), por lo que uso row[0] para extraer el ID de cada tupla y crear una lista de IDs.\n",
    "# Insertar libros y relaciones M2M\n",
    "libros_insertados_count = 0\n",
    "for libro_item in lista_datos_libros:   # Itera sobre cada libro en los datos scrapeados\n",
    "    if \"categoria\" not in libro_item or \"autor_scrapeado\" not in libro_item:    # Verifica que el libro tenga categoría y autor\n",
    "        continue\n",
    "\n",
    "    cursor_operaciones.execute(\"SELECT id FROM Categorias WHERE nombre=?\", (libro_item[\"categoria\"],))  # Obtiene el ID de la categoría\n",
    "    id_categoria_obtenida = cursor_operaciones.fetchone()[0]  #fetchone() me retorna una tupla con una sola columna, y con [0] extraigo el valor del ID para usarlo \n",
    "    \n",
    "    cursor_operaciones.execute(\"SELECT id FROM Autores WHERE nombre=?\", (libro_item[\"autor_scrapeado\"],)) \n",
    "    id_autor_principal = cursor_operaciones.fetchone()[0] # Obtiene el ID del autor principal\n",
    "\n",
    "    cursor_operaciones.execute(\"\"\"\n",
    "        INSERT INTO Libros(titulo, precio, calificacion, stock, id_categoria) \n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\", (libro_item[\"titulo\"], libro_item[\"precio\"], libro_item[\"calificacion\"], libro_item[\"stock\"], id_categoria_obtenida)) # Inserta el libro en la tabla Libros, con sus datos correspondientes\n",
    "    \n",
    "    id_libro_obtenido = cursor_operaciones.lastrowid # Obtiene el ID del libro recién insertado\n",
    "\n",
    "    # Autor principal\n",
    "    cursor_operaciones.execute(\"\"\"              # Inserta la relación libro-autor principal\n",
    "        INSERT OR IGNORE INTO Libro_Autor(id_libro, id_autor) VALUES (?, ?)\n",
    "    \"\"\", (id_libro_obtenido, id_autor_principal))         # Inserta la relación libro-autor principal\n",
    "\n",
    "    # Relleno de la relacion de muchos a muchpos: 30% de probabilidad\n",
    "    if random.random() < 0.3:              # 30% de probabilidad\n",
    "        num_autores_extra = random.randint(1, 2)         # Número aleatorio de autores extra (1 o 2)\n",
    "        autores_extra = random.sample(ids_autores_ficticios, num_autores_extra)         #sample garantiza que no se repitan , los ids de los autores ficticios\n",
    "        for id_extra in autores_extra: \n",
    "            if id_extra != id_autor_principal: # Evita duplicados\n",
    "                cursor_operaciones.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO Libro_Autor(id_libro, id_autor) VALUES (?, ?)\n",
    "                \"\"\", (id_libro_obtenido, id_extra)) # Inserta la relación libro-autor extra\n",
    "    \n",
    "    libros_insertados_count += 1\n",
    "\n",
    "conexion_base_datos.commit()         # Guarda todos los cambios en la base de datos\n",
    "print(f\"Base de datos poblada con {libros_insertados_count} libros y relaciones M2M simuladas.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conexion = sqlite3.connect(\"libros.db\")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT a.nombre AS autor, l.titulo AS libro, l.calificacion\n",
    "FROM Libros l\n",
    "JOIN Libro_Autor la ON l.id = la.id_libro\n",
    "JOIN Autores a ON la.id_autor = a.id\n",
    "WHERE l.calificacion = 1\n",
    "ORDER BY a.nombre;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "resultados = cursor.fetchall()\n",
    "\n",
    "# Mostrar resultados sin que aparezca \"Add a comment ->\"\n",
    "for i, (autor, libro, calificacion) in enumerate(resultados, 1):\n",
    "    print(f\"{i}. {autor} -> {libro} ({calificacion} estrella)\")\n",
    "\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f7b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conexion = sqlite3.connect(\"libros.db\")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Consulta: libros con más de 3 estrellas y precio < 10\n",
    "query = \"\"\"\n",
    "SELECT titulo, precio, calificacion\n",
    "FROM Libros\n",
    "WHERE calificacion > 3 AND precio < 10\n",
    "ORDER BY calificacion DESC, precio ASC;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "resultados = cursor.fetchall()\n",
    "\n",
    "for i, fila in enumerate(resultados, 1):\n",
    "    print(f\"{i}. {fila[0]} -> £{fila[1]} ({fila[2]} estrellas)\")\n",
    "\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conexion = sqlite3.connect(\"libros.db\")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT a.nombre, COUNT(la.id_libro) AS total_libros\n",
    "FROM Autores a\n",
    "JOIN Libro_Autor la ON a.id = la.id_autor\n",
    "GROUP BY a.nombre\n",
    "ORDER BY total_libros DESC;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "resultados = cursor.fetchall()\n",
    "\n",
    "for autor, total in resultados:\n",
    "    print(f\"{autor} -> {total} libros\")\n",
    "\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conexion = sqlite3.connect(\"libros.db\")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT c.nombre AS categoria, AVG(l.calificacion) AS promedio\n",
    "FROM Categorias c\n",
    "JOIN Libros l ON c.id = l.id_categoria\n",
    "GROUP BY c.nombre\n",
    "ORDER BY promedio DESC;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "resultados = cursor.fetchall()\n",
    "for i, fila in enumerate(resultados, 1):\n",
    "    print(f\"{i}. {fila[0]} -> promedio {fila[1]:.2f}\")\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e61329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo sin índice: 0.00525 segundos\n",
      "Tiempo con índice: 0.00201 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sqlite3\n",
    "conexion = sqlite3.connect(\"libros.db\")\n",
    "\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# ---- Sin índice ----\n",
    "inicio = time.time()\n",
    "cursor.execute(\"SELECT * FROM Libros WHERE calificacion = 5;\")\n",
    "cursor.fetchall()\n",
    "fin = time.time()\n",
    "print(f\"Tiempo sin índice: {fin - inicio:.5f} segundos\")\n",
    "\n",
    "# ---- Crear índice ----\n",
    "cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_calificacion ON Libros(calificacion);\")\n",
    "conexion.commit()                         #índice de materias, que permite saltar directo a lo que te interesa sin leer todo\n",
    "\n",
    "# ---- Con índice ----\n",
    "inicio = time.time()\n",
    "cursor.execute(\"SELECT * FROM Libros WHERE calificacion = 5;\")\n",
    "cursor.fetchall()\n",
    "fin = time.time()\n",
    "print(f\"Tiempo con índice: {fin - inicio:.5f} segundos\")\n",
    "\n",
    "conexion.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
